\chapter{Sviluppo del prodotto}
\label{cap:product-development}

\intro{In questo capitolo vengono approfondite le fasi di sviluppo del sistema, descrivendo l'architettura complessiva, le fasi di implementazione e i risultati ottenuti}

\section{Architettura complessiva del sistema}
L'architettura realizzata durante il tirocinio ha l'obiettivo di fornire un sistema completo di osservabilità per la \emph{web app PetClinic}, integrando in un ambiente unico la raccolta dei log, metriche, tracce e monitoraggio sintetico. \\
Per raggiungere questo obiettivo è stato utilizzato l'ecosistema \emph{Elastic Stack}, \emph{Docker} e \emph{OpenTelemetry}. \\
L'applicazione \emph{PetClinic} è strumentata tramite l'\emph{OpenTelemetry Java Agent}, che esporta metriche e tracce verso un \emph{OpenTelemetry Collector}. Quest'ultimo funge da punto di aggregazione e inoltra i dati al sistema \gls{apm} gestito da \emph{Elastic Agent} tramite \emph{Fleet}. \\
In parallelo, i log dell'applicazione vengono scritti su un file locale dal \emph{container} \emph{PetClinic} e successivamente raccolti da \emph{Logstash}, che li elabora e li inoltra verso \emph{Elasticsearch} seguendo una \emph{pipeline} personalizzata. \\
Per quanto riguarda la visualizzazione dei dati, è stato utilizzato \emph{Kibana}, tramite cui è possibile monitorare l'andamento dell'applicazione, creare \emph{dashboard}, analizzare metriche di \emph{performance}, effettuare ricerche sui log ed eseguire attività di \emph{anomaly detection}. \\
Accanto ai dati reali provenienti dall'applicazione, è stato integrato un sistema di \emph{Synthetic Monitoring} basato su \emph{Kibana Synthetics}, che utilizza \emph{script Playwright} per simulare il comportamento degli utenti e verificare la disponibilità e il corretto funzionamento dei principali flussi di navigazione. Trattandosi di un applicazione di prova infatti l'utilizzo di monitoraggio sintetico permette di lavorare con una quantità più significativa di dati. \\
Nel complesso, l'architettura si presenta come una \emph{pipeline} altamente modulare, in cui ogni componente è orchestrato tramite \emph{Docker Compose}. Questa struttura rende l'ambiente facilmente replicabile, facilitando sia le attività di sviluppo che quelle di \emph{troubleshooting}.
\begin{figure}[H] 
    \centering 
    \includegraphics[width=\columnwidth]{Architettura_complessiva.png}
    \caption{Figura 5.1 - Architettura complessiva}
\end{figure}

\newpage


\section{Struttura del progetto}
La realizzazione del sistema di osservabilità è stata accompagnata dalla definizione di una struttura del progetto che ne facilitasse lo sviluppo e le attività di manutenzione. \\
Il repository principale, chiamato \emph{elastic-project}, contiene tutte le componenti necessarie all'avvio tramite \emph{Docker Compose} e alla configurazione delle \emph{pipelines} di log, metriche e tracce, nonché all'avvio delle istanze del \emph{Fleet Server} e delle \emph{policy} per il \emph{Synthetic monitoring}. \\
La struttura complessiva è riportata di seguito:
\begin{lstlisting}[basicstyle=\ttfamily\small]
- elastic-project/ 
-- docker-compose.yml
-- .env
-- logstash.conf
-- logs/
-- collector/
    -> config.yaml
-- mcp-server-elasticsearch/
-- spring-petclinic/
    -> Dockerfile
\end{lstlisting}

Questa organizzazione è stata costruita con l'obiettivo di isolare le responsabilità dei vari componenti:
\begin{itemize}
    \item \textbf{docker-compose.yml} rappresenta il file principale per l'orchestrazione dei \emph{container}, in cui vengono definiti i servizi fondamentali. La scelta di accorpare tutti i servizi in un unico file semplifica la fase di avvio e garantisce un ambiente riproducibile;
    \item \textbf{spring-petclinic/} contiene il codice dell'applicazione \emph{PetClinic} e il relativo \emph{Dockerfile} per la creazione dell'immagine personalizzata con l'\emph{OpenTelemetry Java Agent} integrato;
    \item \textbf{collector/} include la configurazione dell'\emph{OpenTelemetry Collector} nel file \emph{config.yaml}, responsabile della ricezione dei dati \gls{otlp} provenienti da \emph{PetClinic} e del loro inoltro al sistema \gls{apm} gestito da \emph{Fleet};
    \item \textbf{logstash.conf} definisce la \emph{pipeline} di \emph{Logstash} che legge e filtra i log dell'applicazione, applicando un primo livello di arricchimento e inviando i dati a \emph{Elasticsearch};
    \item \textbf{logs/} funge da volume locale in cui l'applicazione \emph{PetClinic} rende disponibili i file di log;
    \item \textbf{mcp-server-elasticsearch/} contiene i file necessari per l'esecuzione del \emph{server} \gls{mcpg}\glsfirstoccur dedicato a \emph{Elasticsearch}, che abilita l'interazione con strumenti di \gls{ai} generativa come \emph{Claude Code};
    \item \textbf{.env} contiene le variabili d'ambiente necessarie per la configurazione dei servizi.
\end{itemize}
Questa struttura ha permesso di lavorare in modo indipendente sulle singole componenti del sistema senza introdurre interferenze tra servizi, e ha contribuito a semplificare la fase di diagnosi dei problemi.

\newpage


\section{Implementazione del logging}
L'implementazione della \emph{pipeline} di raccolta e indicizzazione dei log applicativi rappresenta un passaggio fondamentale del sistema di osservabilità sviluppato. \\
L'obiettivo principale era quello di acquisire i log generati da \emph{Spring PetClinic}, arricchirli con metadati utili, e renderli disponibili per la consultazione e l'analisi tramite \emph{Kibana}. \\
Per ottenere questo risultato è stata realizzata una \emph{pipeline} composta da tre elementi principali:
\begin{enumerate}
    \item scrittura dei log nel \emph{container PetClinic}, in un percorso montato come volume esterno;
    \item raccolta ed elaborazione dei log tramite \emph{Logstash}, configurato con un file di \emph{pipeline} dedicato;
    \item indicizzazione dei log in \emph{Elasticsearch} tramite una struttura di indici gestita con \gls{ilmg}\glsfirstoccur e un \emph{template} personalizzato.
\end{enumerate}

\subsection{Scrittura dei log applicativi}
Il primo passo ha riguardato la configurazione di \emph{PetClinic} affinché producesse log su file, in modo da poterli acquisire tramite \emph{Logstash}.
Il \emph{Dockerfile} dell'applicazione è stato modificato aggiungendo il parametro \texttt{-Dlogging.file.name=/var/log/petclinic/app.log} alla riga di comando di avvio. \\
Questo approccio ha permesso di centralizzare i log in un unico file, esporlo come volume condiviso e separare la fase di generazione dei log dalla loro elaborazione. 

\subsection{Pipeline Logstash}
La raccolta e trasformazione dei log è stata implementata tramite \emph{Logstash}, attraverso un file di configurazione dedicato \texttt{logstash.conf}:
\begin{lstlisting}
input {
  file {
    path => "/var/log/petclinic/app.log"
    start_position => "beginning"
    sincedb_path   => "/usr/share/logstash/data/sincedb-petclinic"
  }
}

filter {
  mutate {
    add_field => {
      "service.name"      => "petclinic"
      "event.dataset"     => "petclinic.app"
      "data_stream.type"  => "logs"
      "data_stream.dataset" => "petclinic"
      "data_stream.namespace" => "default"
    }
  }
}

output {
  stdout { codec => rubydebug }

  elasticsearch {
    hosts    => [ "${ELASTIC_HOSTS}" ]
    user     => "${ELASTIC_USER}"
    password => "${ELASTIC_PASSWORD}"
    ssl      => true
    cacert   => "/usr/share/logstash/certs/ca/ca.crt"
    index    => "petclinic-logs"
  }
}
\end{lstlisting}
La pipeline si articola in tre fasi: input, filtro e output.

\paragraph{Input:}
Viene utilizzato il plugin \texttt{file} per monitorare il file \texttt{app.log} generato dall'applicazione.  
Il file viene letto dall'inizio e l'avanzamento è tracciato tramite un file \texttt{sincedb}, così da evitare duplicazioni in caso di riavvio.

\paragraph{Filter:}
I log vengono arricchiti con metadati aggiuntivi, tra cui:
\begin{itemize}
    \item \texttt{service.name},
    \item \texttt{event.dataset},
    \item campi relativi ai data stream di \emph{Elasticsearch}.
\end{itemize}
Queste informazioni migliorano la struttura dei documenti, permettendo un'analisi più efficace e una migliore organizzazione dei dati nei \emph{data view}.

\paragraph{Output:}
L'output della pipeline invia i documenti verso \emph{Elasticsearch} tramite l'endpoint \gls{httpsg}\glsfirstoccur, utilizzando credenziali e certificati definiti nel file \texttt{.env}.  
I log vengono scritti sull'alias \texttt{petclinic-logs}, gestito successivamente tramite \gls{ilmg}.

\subsection{Struttura degli indici in Elasticsearch}
Prima dell'invio dei log è stata predisposta l'infrastruttura necessaria in \emph{Elasticsearch}.

\paragraph{Policy ILM:}
È stata definita una policy di gestione del ciclo di vita dell'indice (\emph{Index Lifecycle Management}) in grado di:
\begin{itemize}
    \item effettuare \emph{rollover} ogni 1 GB o ogni 24 ore;
    \item eliminare automaticamente i dati più vecchi dopo 7 giorni.
\end{itemize}
strutturata come segue:
\begin{lstlisting}
PUT _ilm/policy/petclinic-logs-ilm
{
  "policy": {
    "phases": {
      "hot": {
        "actions": {
          "rollover": {
            "max_size": "1gb",
            "max_age": "1d"
          }
        }
      },
      "delete": {
        "min_age": "7d",
        "actions": {
          "delete": {}
        }
      }
    }
  }
}
\end{lstlisting}

\paragraph{Index Template:}
È stato creato un \emph{template} denominato \texttt{petclinic-logs-template} per definire:
\begin{itemize}
    \item il numero di \emph{shard} e repliche,
    \item il limite massimo dei campi mappati,
    \item il \emph{mapping} dei principali campi del log,
    \item regole dinamiche per trattare le stringhe come \emph{keyword}.
\end{itemize}
\begin{lstlisting}
PUT _index_template/petclinic-logs-template
{
  "index_patterns": ["petclinic-logs-*"],
  "template": {
    "settings": {
      "index.lifecycle.name": "petclinic-logs-ilm",
      "index.lifecycle.rollover_alias": "petclinic-logs",
      "number_of_shards": 1,
      "number_of_replicas": 0,
      "index.mapping.total_fields.limit": 2000,
    },
    "mappings": {
      "dynamic": true,
      "properties": {
        "@timestamp": {
          "type": "date"
        },

        "message": {
          "type": "text",
          "fields": {
            "keyword": { "type": "keyword", "ignore_above": 256 }
          }
        },

        "log.level":       { "type": "keyword" },
        "log.logger":      { "type": "keyword" },
        "log.thread":      { "type": "keyword" },
        "log.original":    { "type": "text" },

        "service.name":    { "type": "keyword" },
        "event.dataset":   { "type": "keyword" },

        "trace.id": { 
          "type": "keyword",
          "ignore_above": 256
        },
        "span.id": {
          "type": "keyword",
          "ignore_above": 256
        },

        "error": {
          "properties": {
            "type":     { "type": "keyword" },
            "message":  { "type": "text" },
            "stack":    { "type": "text" }
          }
        }
      },

      "dynamic_templates": [
        {
          "strings_as_keywords": {
            "match_mapping_type": "string",
            "mapping": { "type": "keyword", "ignore_above": 256 }
          }
        }
      ]
    }
  },
  "_meta": {
    "description": "Template index per petclinic"
  }
}
\end{lstlisting}

\paragraph{Alias e primo indice:}
È stato infine creato il primo indice gestito dalla \emph{policy} \gls{ilmg}, associato all'\emph{alias} \texttt{petclinic-logs} con \texttt{is\_write\_index = true}, in questo modo \emph{Logstash} scrive sempre nell'\emph{alias}, mentre \emph{Elasticsearch} gestisce la creazione dei nuovi indici tramite \gls{ilmg}:
\begin{lstlisting}
PUT petclinic-logs-000001
{
  "aliases": {
    "petclinic-logs": {
      "is_write_index": true
    }
  }
}
\end{lstlisting}


\subsection{Risultato della pipeline}
La \emph{pipeline} finale dei log può essere sintetizzata nel seguente flusso:
\begin{figure}[H] 
    \centering 
    \includegraphics[width=\columnwidth]{pipeline_logs.png} 
    \caption{Figura 5.2 - Pipeline Logs}
\end{figure}
Grazie a questa configurazione viene garantita un'acquisizione affidabile dei log, un arricchimento consistente delle informazioni e una consultazione efficace tramite \emph{Kibana}.
%\texttt{PetClinic (scrive /var/log/petclinic/app.log) -> Logstash -> Elasticsearch (ILM + index template petclinic-logs-*) -> Kibana (Data View “petclinic-logs”)}

\newpage


\section{Implementazione di traces e metrics}
Parallelamente alla \emph{pipeline} dei log, è stata realizzata una \emph{pipeline} dedicata alla raccolta di metriche e tracce distribuite generate dalla \emph{web app PetClinic}. \\
L'obiettivo è stato quello di ottenere una visione approfondita sui tempi di risposta, sui flussi di esecuzione delle richieste e sulle interazioni tra i componenti del sistema. 
Per raggiungere questo risultato è stato adottato \emph{OpenTelemetry}, integrato con l'\emph{Elastic APM} tramite \emph{Fleet}. \\
La \emph{pipeline} completa è composta dai seguenti elementi:
\begin{enumerate}
    \item strumentazione automatica dell'applicazione tramite \emph{OpenTelemetry Java Agent};
    \item raccolta dei dati \gls{otlpg} (\emph{OpenTelemetry Protocol}) da parte dell'\emph{OpenTelemetry Collector};
    \item inoltro dei dati verso l'\emph{APM Server} gestito dall'\emph{Elastic Agent};
    \item indicizzazione delle metriche e delle tracce in \emph{Elasticsearch} e visualizzazione in \emph{Kibana}.
\end{enumerate}


\subsection{Strumentazione dell'applicazione}
L'applicazione \emph{PetClinic} è stata strumentata utilizzando l'\emph{OpenTelemetry Java Agent}, un agente Java esterno che permette di raccogliere automaticamente metriche e tracce senza modifiche al codice sorgente. \\
Nel \texttt{Dockerfile} dell'applicazione sono stati aggiunti:
\begin{itemize}
    \item il file \texttt{opentelemetry-javaagent.jar};
    \item i parametri di avvio per abilitarne il caricamento e configurarne l'esportazione.
\end{itemize}
Il comando di avvio che viene eseguito dal \texttt{Dockerfile} è il seguente:
\begin{verbatim}
CMD ["java", \
    "-javaagent:/app/opentelemetry-javaagent.jar", \
    "-Dotel.service.name=petclinic", \
    "-Dotel.exporter.otlp.endpoint=http://collector:4318", \
    "-Dotel.exporter.otlp.protocol=http/protobuf", \
    "-Dotel.exporter.otlp.insecure=true", \
    "-Dlogging.file.name=/var/log/petclinic/app.log", \
    "-jar", "/app/app.jar"]
\end{verbatim}
Grazie a questa configurazione, l'applicazione esporta automaticamente:
\begin{itemize}
    \item metriche sulle performance (\gls{cpug}, \emph{heap}, ecc);
    \item tracce delle richieste \gls{httpg} in ingresso;
    \item eventi relativi agli errori e alle eccezioni.
\end{itemize}


\subsection{RUM Agent frontend}
Oltre ai dati provenienti dal backend tramite l'\emph{OpenTelemetry Java Agent}, la \emph{pipeline} raccoglie anche metriche, errori e tracce generate dal \emph{frontend} dell'applicazione attraverso il \emph{RUM Agent} di \emph{Elastic APM}. \\
Il \emph{RUM Agent}, integrato direttamente nelle pagine \emph{web}, invia i dati di \emph{performance} del \emph{browser}, la durata delle transazioni utente, gli errori \emph{JavaScript} e le informazioni sulla navigazione direttamente all'\emph{APM Server}. \\
Il \emph{RUM Agent}, a differenza dell'\emph{OpenTelemetry Collector}, comunica nativamente con il protocollo \emph{Elastic APM} e invia i dati direttamente all'endpoint \gls{apmg}, senza transitare attraverso il \emph{Collector}. \\
Entrambe le sorgenti, confluiscono nei data stream \texttt{traces-apm*} e \texttt{metrics-apm*}, permettendo una visione unificata delle performance sia del \emph{backend} sia del \emph{frontend}.


\subsection{OpenTelemetry Collector}
Il \emph{Collector} funge da punto di raccolta per i dati \gls{otlpg} provenienti dalla \emph{web app}. 
In questo progetto è stato configurato in modalità \emph{gateway}, aggregando i dati e inoltrandoli al sistema \gls{apmg} gestito da \emph{Elastic}. \\
Il file \texttt{config.yaml} definisce i seguenti componenti principali:
\begin{itemize}
    \item un \texttt{receiver} \gls{otlpg} (\gls{httpg} e \gls{grpcg}\glsfirstoccur) per ricevere i dati dall'applicazione;
    \item un processore \texttt{memory\_limiter} per evitare sovraccarichi;
    \item un processore \texttt{batch} per inviare i dati in blocchi ottimizzati;
    \item un \texttt{exporter} \texttt{otlphttp/elastic} diretto verso il container \texttt{apm-agent}.
\end{itemize}
Il \emph{collector} è eseguito come servizio dedicato nel \texttt{docker-compose}, con volume in sola lettura. \\
Ecco la configurazione completa:
\begin{lstlisting}
receivers:
  otlp:
    protocols:
      grpc:
        endpoint: 0.0.0.0:4317
      http:
        endpoint: 0.0.0.0:4318
        cors:
          allowed_origins: ["http://localhost:*", "http://127.0.0.1:*", "*"]
          allowed_headers: ["*"]

processors:
  memory_limiter:
    check_interval: 2s
    limit_percentage: 80
    spike_limit_percentage: 25
  batch:
    timeout: 2s
    send_batch_size: 1024


exporters:
  otlphttp/elastic:
    endpoint: "http://apm-agent:8200"
    tls:
      insecure: true

service:
  pipelines:
    traces:
      receivers: [otlp]
      processors: [memory_limiter, batch]
      exporters: [otlphttp/elastic]
    metrics:
      receivers: [otlp]
      processors: [memory_limiter, batch]
      exporters: [otlphttp/elastic]
    logs:
      receivers: [otlp]
      processors: [memory_limiter, batch]
      exporters: [otlphttp/elastic]
\end{lstlisting}


\subsection{Elastic Agent e APM Server}
Il sistema \gls{apmg} di \emph{Elastic} è gestito tramite l'\emph{Elastic Agent} registrato in \emph{Fleet}. 
Nel progetto è stato utilizzato un \emph{container} dedicato (\texttt{apm-agent}) configurato per:
\begin{itemize}
    \item registrarsi automaticamente presso il \emph{Fleet Server} tramite \emph{enrollement token};
    \item esporre l'\emph{endpoint} \gls{apmg} sulla porta 8200;
    \item ricevere dati \gls{otlpg} dal \emph{Collector}.
\end{itemize}
L'\emph{APM Server} è responsabile di:
\begin{itemize}
    \item validare metriche e tracce in arrivo;
    \item convertirle nei documenti \emph{Elasticsearch};
    \item indicizzarle automaticamente in base ai moduli di ingesione dello \emph{stack Elastic}.
\end{itemize}
La corretta registrazione del \emph{container} in \emph{Fleet} è un prerequisito per il funzionamento della \emph{pipeline}, a tal fine, è stata dedicata un'apposita \emph{policy APM}.


\subsection{Indicizzazione e visualizzazione dei dati in Kibana}
Una volta ricevuti dal sistema \gls{apmg}, i dati vengono indicizzati in \emph{Elasticsearch} nei \emph{data stream}:
\begin{itemize}
    \item \texttt{traces-apm*} per le tracce distribuite;
    \item \texttt{metrics-apm*} per le metriche;
    \item \texttt{logs-apm*} per eventuali eventi generati dall'agente.
\end{itemize}
Questi indici vengono raccolti automaticamente nella data view \texttt{APM}, fornita nativamente dalla piattaforma.


\subsection{Risultato della pipeline}
Il flusso risultante può essere sintetizzato come segue:
\begin{figure}[H] 
    \centering 
    \includegraphics[width=\columnwidth]{pipeline_traces_metrics.png} 
    \caption{Figura 5.3 - Pipeline Traces e Metrics}
\end{figure}

\newpage


\section{Containerizzazione con Docker Compose}
L'intera infrastruttura di osservabilità è stata containerizzata utilizzando \emph{Docker Compose}, con lo scopo di ottenere un ambiente completamente riproducibile, isolato e facilmente avviabile. \\
Il file \texttt{docker-compose.yml} rappresenta il punto centrale dell'orchestrazione e descrive un insieme eterogeneo di servizi che lavorano assieme, tra cui:
\begin{itemize}
    \item \texttt{es01}: nodo \emph{Elasticsearch} responsabile della memorizzazione dei log, delle metriche e delle tracce;
    \item \texttt{kibana}: interfaccia grafica per la visualizzazione dei dati;
    \item \texttt{fleet-server}: servizio dedicato alla gestione centralizzata degli agenti \emph{Elastic};
    \item \texttt{apm-agent}: componente che espone l'\emph{endpoint APM} per ricevere metriche e tracce dal \emph{Collector} e dal \emph{RUM Agent};
    \item \texttt{collector}: \emph{OpenTelemetry Collector} configurato in modalità \emph{gateway};
    \item \texttt{logstash01}: responsabile della \emph{pipeline} di elaborazione dei log applicativi;
    \item \texttt{petclinic}: applicazione oggetto del monitoraggio;
    \item \texttt{mysql}: \emph{database} a supporto dell'applicazione;
    \item \texttt{synthetics-agent}: componente dedicato al monitoraggio sintetico;
    \item \texttt{mcp-server-elasticsearch}: server \gls{mcpg} utilizzato per l'integrazione con strumenti di \gls{aig} generativa;
    \item \texttt{setup}: servizio dedicato alla generazione e distribuzione dei certificati \gls{tlsg}.
\end{itemize}


\subsection{Gestione dei certificati e della sicurezza}
Una parte rilevante dell'orchestrazione riguarda la gestione della sicurezza. \\
Il servizio \texttt{setup} genera automaticamente certificati autofirmati e li distribuisce agli altri container attraverso un volume condiviso. Questo passaggio è essenziale poiché i servizi dello \emph{stack Elastic} richiedono comunicazioni cifrate e autenticazione abilitata. \\
Il file \texttt{.env}, incluso nel progetto, contiene inoltre credenziali, porte e parametri di configurazione necessari all'avvio dei container.


\subsection{Coordinamento dell'avvio dei servizi}
La corretta gestione dell'ordine di avvio è stata un aspetto importante della configurazione. Alcuni servizi, come \texttt{fleet-server} e \texttt{apm-agent}, richiedono che \emph{Elasticsearch} sia completamente operativo prima di potersi registrare ed esporre i propri \emph{endpoint}. \\
Questo comportamento è stato gestito tramite direttive \texttt{depends\_on}, healthcheck e l'utilizzo di servizi come \texttt{setup}, che garantiscono la generazione dei certificati necessari al \emph{cluster}. \\
L'uso esplicito delle dipendenze e dei controlli di stato ha reso possibile evitare errori di avvio legati alla sincronizzazione tra i servizi, un problema frequente nelle architetture \emph{multi-container}.


\subsection{Risultato dell'orchestrazione}
L'orchestrazione basata su \emph{Docker Compose} consente di controllare e avviare l'intero ambiente di osservabilità tramite il comando:
\begin{verbatim}
docker compose up -d
\end{verbatim}
Questo approccio ha permesso di ottenere un sistema facilmente estendibile e semplice da mantenere. 

\newpage


\section{Visualizzazione dei dati in Kibana}
Al termine della configurazione delle \emph{pipeline} di log, metriche, tracce e monitoraggio, è stato necessario predisporre in \emph{Kibana} gli strumenti per la visualizzazione e l'analisi dei dati raccolti. \\
Sono stati individuati diversi \emph{data view}, alcuni già presenti di default in \emph{Kibana}, altri appositamente creati per facilitare l'accesso ai vari tipi di dati:
\begin{itemize}
    \item \texttt{traces-apm*}, fornita nativamente da Kibana, contenente le tracce distribuite provenienti dal \emph{backend} e dal \emph{frontend};
    \item \texttt{metrics-apm*}, fornita nativamente da Kibana, relativa alle metriche di sistema raccolte dall'\emph{OpenTelemetry Java Agent};
    \item \texttt{logs-apm*}, fornita nativamente da Kibana, include eventuali eventi generati dagli agenti \emph{Elastic};
    \item \texttt{petclinic-logs-*}, \emph{data view} dedicato ai log applicativi raccolti tramite \emph{Logstash} e indicizzati in \emph{Elasticsearch}.
\end{itemize}
Per facilitare l'analisi, sono state create due viste dati principali:
\begin{itemize}
    \item \textbf{APM}: fornita nativamente da \emph{Kibana}, che aggrega metriche, tracce ed errori provenienti dal \emph{backend}, dal \emph{frontend} e dal monitoraggio sintetico;
    \item \textbf{petclinic-logs}: vista personalizzata per l'esplorazione dei log applicativi indicizzati tramite la \emph{pipeline} \emph{Logstash}.
\end{itemize}


\subsection{Verifica dell'indicizzazione tramite Dev Tools}
Dopo l'avvio dei servizi, è stata effettuata una verifica manuale dell'indicizzazione tramite la console \emph{Dev Tools} di \emph{Kibana}. \\
Questo controllo è stato utile per confermare il corretto funzionamento della \emph{pipeline} di log e verificare che i documenti fossero instradati verso il data stream appropriato. \\
Alcuni esempi di query utilizzate sono:
\begin{itemize}
  \item \texttt{GET petclinic-logs-*/\_search?size=5} per verificare che i documenti applicativi arrivino all'indice corretto;
  \item \texttt{GET petclinic-logs-*/\_mapping} per verificare che il \emph{mapping} dei campi sia in linea con il template di indicizzazione.
\end{itemize}
La risposta di Elasticsearch ha confermato che:
\begin{itemize}
    \item \emph{Logstash} stava correttamente inviando i log verso l'alias \texttt{petclinic-logs};
    \item il \emph{Collector} e il \emph{RUM Agent} inviavano correttamente le tracce all'\emph{APM Server};
    \item tutti i documenti venivano mappati in base al \emph{template} configurato.
\end{itemize}

\newpage


\section{Creazione delle dashboard}
All'interno della sezione \emph{Analytics --> Dashboards} di \emph{Kibana} sono state realizzate due \emph{dashboard} dedicate all'analisi e alla visualizzazione dei dati raccolti dal \emph{data view} \gls{apmg}. \\
Le \emph{dashboard} hanno lo scopo di fornire una panoramica del comportamento dell'applicazione sia dal punto di vista dell'utente finale sia dal punto di vista delle \emph{performance} e della stabilità lato \emph{server}.


\subsection{Dashboard Frontend - User Journey}
La \emph{dashboard} dedicata al \emph{frontend} analizza il comportamento degli utenti e le \emph{performance} percepite dal \emph{browser} tramite i dati raccolti dal \emph{RUM Agent}. \\
Essa comprende cinque visualizzazioni principali:
\begin{itemize}
    \item \textbf{Funnel di navigazione}: con l'asse X impostato su \texttt{transaction.name} e l'asse Y sul \texttt{countof(records)}, per rappresentare i percorsi più frequenti;
    \item \textbf{Tempo di caricamento per pagina}: con \texttt{url.full} sull'asse X e \texttt{avg(transaction.duration.us)} sull'asse Y;
    \item \textbf{Errori JavaScript per browser}: con \texttt{countof(error.id)} sull'asse Y e \texttt{user\_agent.name} sull'asse X;
    \item \textbf{Interazioni per tipo}: basata su \texttt{span.name} sull'asse X e \texttt{countof(records)} sull'asse Y;
    \item \textbf{Distribuzione dei browser per indirizzo IP}: utilizzata per analizzare la provenienza e l'ambiente \emph{client} delle sessioni.
\end{itemize}
\begin{figure}[H] 
    \centering 
    \includegraphics[width=\columnwidth]{/dashboards/Frontend_dashboard.png}
    \caption{Figura 5.4 - Dashboard Frontend - User Journey}
\end{figure}

\newpage

\subsection{Dashboard Backend - Health \& Stability}
La \emph{dashboard} relativa al \emph{backend} fornisce invece una panoramica dello stato di salute della \emph{web app} e delle sue \emph{performance} lato \emph{server}. \\ 
Anche in questo caso sono presenti cinque visualizzazioni:
\begin{itemize}
    \item \textbf{Tempo medio di risposta per endpoint}: con \texttt{url.path} in X e \texttt{avg(transaction.duration.us)} in Y;
    \item \textbf{Errori per tipo di eccezione}: con \texttt{error.exception.type} rappresentato in un grafico a torta;
    \item \textbf{Chiamate lente} (oltre 2 secondi): identificate tramite un filtro su \texttt{transaction.duration.us >= 2000000} e rappresentate in formato tabellare;
    \item \textbf{Distribuzione delle richieste per metodo HTTP}: basata su \texttt{http.request.method} in un grafico a torta;
    \item \textbf{Conteggio totale delle richieste}: che fornisce una vista aggregata dei volumi di traffico applicativo.
\end{itemize}
\begin{figure}[H] 
    \centering 
    \includegraphics[width=\columnwidth]{/dashboards/Backend_dashboard.png} 
    \caption{Figura 5.5 - Dashboard Backend - Health \& Stability}
\end{figure}
Le due dashboard costituiscono un insieme di strumenti utili per comprendere il comportamento dell'applicazione in condizioni reali, individuare potenziali anomalie e monitorare l'esperienza utente e la stabilità del sistema.

\newpage


\section{Machine Learning e Anomaly Detection}
All'interno dell'infrastruttura è stato integrato il modulo di \emph{Machine Learning} di \emph{Kibana} con lo scopo di identificare automaticamente comportamenti anomali nei dati raccolti. \\
Questa funzionalità fa parte della versione premium dell'\emph{Elastic stack} messa a disposizione dall'azienda e consente di rafforzare la capacità di monitoraggio della piattaforma, introducendo un livello di analisi predittiva che va oltre le normali visualizzazioni fornite in \emph{Kibana}.


\subsection{Anomaly Detection Jobs}
Sono stati configurati due \emph{job} distinti, ognuno progettato per analizzare un diverso aspetto del comportamento dell'applicazione:
\begin{itemize}
    \item \textbf{anomaly\_transactions}: \emph{job} di tipo \emph{multimetric} con partizionamento per \texttt{transaction.name}.  
    Analizza la durata mediana delle transazioni con l'obiettivo di rilevare rallentamenti anomali per singolo \emph{endpoint}.  
    Gli \emph{influencer} configurati (\texttt{transaction.name} e \texttt{service.name}) permettono di identificare rapidamente quale operazione contribuisce maggiormente alla deviazione osservata.

    \item \textbf{error\_rate\_detection}: \emph{job} di tipo \emph{single metric} orientato alla rilevazione di anomalie nel tasso di errori delle transazioni.  
    Il job analizza l'andamento storico delle occorrenze di errore e segnala incrementi inaspettati rispetto al comportamento atteso.
\end{itemize}
Entrambi i \emph{job} operano in modalità continua, aggiornando costantemente il modello statistico in funzione dei dati più recenti e assegnando un \emph{anomaly score} agli eventi fuori norma.


\subsection{Regole di alerting}
Per ciascun \emph{job} è stata definita una regola di \emph{alerting} dedicata basata sugli \emph{anomaly records}.  
La regola si attiva quando lo \emph{anomaly score} supera una soglia configurata, generando una notifica all'interno di Kibana e via email.  
Ogni alert include informazioni su:
\begin{itemize}
    \item livello di anomalia;
    \item metrica o transazione coinvolta;
    \item valore osservato e valore previsto;
    \item link diretto alla sezione di dettaglio del \emph{job}.
\end{itemize}


\subsection{Benefici per il monitoraggio}
L'integrazione del modulo \gls{mlg}\glsfirstoccur fornisce alla piattaforma di osservabilità uno strato di analisi avanzato capace di:
\begin{itemize}
    \item individuare anomalie graduali o intermittenti difficili da rilevare manualmente;
    \item evidenziare rallentamenti e incrementi del tasso di errore prima che impattino direttamente l'utente finale;
    \item fornire una spiegazione del problema tramite gli \emph{influencer} e i grafici di contributo.
\end{itemize}

\newpage


\section{Synthetic Monitoring}
Il \emph{Synthetic Monitoring} è stato utilizzato per simulare in modo automatico le interazioni degli utenti con \emph{PetClinic}, per monitorarne la disponibilità, i tempi di risposta e il corretto funzionamento. \\ 
La configurazione è stata effettuata all'interno della sezione \emph{Observability --> Synthetics --> Monitors} di \emph{Kibana}, dove sono stati creati sette \emph{monitor} dedicati ai percorsi di navigazione più rilevanti.


\subsection{Creazione dei monitor}
\emph{Kibana} consente di definire \emph{monitor} sintetici caricando uno \emph{script JavaScript} o scrivendolo direttamente nell'interfaccia. \\
Per la generazione degli \emph{script} è stato utilizzato \emph{Synthetics Recorder}, strumento nativo che registra le azioni dell'utente nel \emph{browser} ed esporta automaticamente codice \emph{Playwright} pronto per l'esecuzione. \\
Questa soluzione si è dimostrata più efficiente rispetto ad alternative come \emph{Katalon}, che forniva esportazioni non compatibili (es.\ \emph{Python2}) oppure \emph{Selenium}. \\
Ogni \emph{monitor} esegue uno \emph{script} \emph{Playwright} che riproduce una sequenza di azioni definite: apertura della \emph{homepage}, navigazione nei menu, ricerca di proprietari, inserimento di nuovi dati e visualizzazione delle sezioni dedicate ai veterinari.


\subsection{Flussi monitorati}
Sono stati implementati sette monitor, ciascuno focalizzato su un flusso specifico:
\begin{itemize}
    \item \textbf{owners}: navigazione nella sezione \emph{Find Owners} e consultazione dei profili;
    \item \textbf{add\_owner}: inserimento di un nuovo proprietario tramite il form dell'applicazione;
    \item \textbf{add\_owner\_pet}: creazione di un proprietario e aggiunta di un nuovo animale;
    \item \textbf{find}: ricerca di un proprietario tramite il campo \emph{lastName};
    \item \textbf{home}: verifica del caricamento della \emph{homepage};
    \item \textbf{navigation}: navigazione sequenziale tra \emph{Home, Find Owners, Veterinarians, Error} e ritorno alle sezioni principali;
    \item \textbf{veterinarians}: esplorazione della pagina dei veterinari e delle sue sottosezioni.
\end{itemize}
Ciascun monitor esegue ad intervalli di tempo regolari il relativo \emph{script}, registrando attività nell'applicazione, che a sua volta invia le metriche e i risultati prodotti a \emph{Elasticsearch} secondo le pipeline previste, consentendo di analizzare la disponibilità dell'applicazione, i tempi di risposta e l'eventuale presenza di errori direttamente nella sezione \emph{Synthetics} di \emph{Kibana}. \\
Un esempio di script utilizzato per il monitor \textbf{add\_owner\_pet} è il seguente:
\begin{lstlisting}
step('Go to petclinic and add owner + pet', async () => {
  await page.goto('http://petclinic:8080/');
  await page.getByRole('link', { name: 'Find Owners' }).click();
  await page.getByRole('link', { name: 'Add Owner' }).click();
  await page.getByLabel('First Name').click();
  await page.getByLabel('First Name').fill('Mark');
  await page.getByLabel('Last Name').click();
  await page.getByLabel('Last Name').fill('Cole');
  await page.getByLabel('Address').click();
  await page.getByLabel('Address').fill('Via Roma 1');
  await page.getByLabel('City').click();
  await page.getByLabel('City').fill('Roma');
  await page.getByLabel('Telephone').click();
  await page.getByLabel('Telephone').fill('0000000000');
  await page.getByRole('button', { name: 'Add Owner' }).click();
  await page.getByRole('link', { name: 'Add New Pet' }).click();
  await page.getByLabel('Name').click();
  await page.getByLabel('Name').fill('Bob');
  await page.getByLabel('Birth Date').fill('2025-10-10');
  await page.getByLabel('Type').selectOption('hamster');
  await page.getByRole('button', { name: 'Add Pet' }).click();
});
\end{lstlisting}

\subsection{Benefici per il monitoraggio}
L'integrazione del \emph{Synthetic Monitoring} garantisce un ulteriore livello di controllo, complementare a metriche, tracce e log. 
Grazie ai monitor sintetici è possibile infatti rilevare:
\begin{itemize}
    \item rallentamenti o interruzioni nei percorsi chiave dell'applicazione;
    \item problemi lato \gls{uig}\glsfirstoccur o di caricamento delle pagine;
    \item differenze di comportamento tra esecuzioni consecutive.
\end{itemize}
Questo approccio consente di simulare l'esperienza dell'utente finale e di individuare rapidamente anomalie che potrebbero impattare sulla disponibilità complessiva del servizio, oltre ad aumentare il numero di dati di telemetria disponibili.

\newpage


\section{Integrazione con MCP Server e strumenti AI}
Durante il periodo di stage è stata analizzata la possibilità di integrare la piattaforma di osservabilità con strumenti di intelligenza artificiale generativa basati sul protocollo \gls{mcpg} (Model Context Protocol). 
Tale integrazione sarebbe utile per abilitare funzionalità avanzate come il riassunto dei log e l'interazione con i dati tramite agenti conversazionali.


\subsection{Limitazioni della versione 8.15 dello stack}
In fase di analisi è emerso che le funzionalità \gls{aig} più recenti come gli \emph{Elastic AI Agents}, l'\emph{AI Assistant} integrato in \emph{Kibana} e le automazioni basate su agenti sono disponibili solo a partire dalla versione \textbf{9.2} dello \emph{stack Elastic}. \\  
Tuttavia, questa versione non è stata adottata nel progetto per due motivi principali:
\begin{itemize}
    \item non tutte le immagini \emph{Docker} necessarie risultano ancora disponibili o stabili per un ambiente completamente containerizzato;
    \item la clientela dell'azienda presso cui è stato svolto lo stage utilizza stabilmente versioni \textbf{8.x}, rendendo necessaria la compatibilità con tale ecosistema.
\end{itemize}
Per questi motivi l'integrazione con gli strumenti \gls{aig} nativi dello \emph{stack} non è stata implementata, pur essendo stata valutata e studiata.


\subsection{Avvio e configurazione del MCP server}
Nonostante l'impossibilità di utilizzare le funzionalità \gls{aig} avanzate, è stata preparata una procedura per l'inizializzazione corretta dell'\emph{MCP Server} con \emph{Elastic 8.15.3}, con l'obiettivo di predisporre l'infrastruttura per futuri sviluppi. \\
La procedura include:
\begin{itemize}
    \item l'avvio del container \texttt{mcp-server-elasticsearch} tramite \emph{docker compose};
    \item la configurazione delle variabili d'ambiente per autenticazione ed \emph{endpoint};
    \item la registrazione del \emph{server MCP} con un \emph{client} compatibile.
\end{itemize}
Questa fase ha permesso di verificare la piena compatibilità del \emph{server MCP} con \emph{Elasticsearch 8.15} e di documentare i prerequisiti per una futura attivazione delle funzionalità \gls{aig}.


\subsection{Risultati e prospettive}
La configurazione del \emph{server MCP} costituisce una base solida per eventuali evoluzioni del progetto verso l'impiego di agenti di intelligenza artificiale direttamente all'interno di \emph{Kibana}, non appena tali strumenti saranno pienamente supportati in versioni stabili dello \emph{stack Elastic}. \\
L'infrastruttura realizzata è quindi predisposta per integrare funzionalità di analisi e automazione, mantenendo allo stesso tempo la compatibilità con gli ambienti utilizzati in produzione dall'azienda.

\newpage


\section{Sintesi dei flussi end-to-end}
La Figura \ref{fig:sintesi-flussi} fornisce una visione complessiva del funzionamento della piattaforma di osservabilità realizzata. \\
Il diagramma integra tutte le \emph{pipeline} sviluppate durante il progetto, ovvero la raccolta di metriche, tracce e log, il monitoraggio sintetico e l'analisi finale, evidenziando il ruolo di ciascun componente e il flusso dei dati dalla sorgente fino alla visualizzazione in \emph{Kibana}.

\begin{figure}[H] 
    \centering 
    \includegraphics[width=\columnwidth]{sintesi_pipeline.png} 
    \caption{Figura 5.6 - Sintesi dei flussi end-to-end}
    \label{fig:sintesi-flussi}
\end{figure}