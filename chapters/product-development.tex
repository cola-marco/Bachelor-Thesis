\chapter{Sviluppo del prodotto}
\label{cap:product-development}

\intro{In questo capitolo vengono approfondite le fasi di sviluppo del sistema, descrivendo l'architettura complessiva, le fasi di implementazione e i risultati ottenuti}

\section{Architettura complessiva del sistema}
L'architettura realizzata durante il tirocinio ha l'obiettivo di fornire un sistema completo di osservabilità per la \emph{web app PetClinic}, integrando in un ambiente unico la raccolta dei log, metriche, tracce e monitoraggio sintetico. \\
Per raggiungere questo obiettivo è stato utilizzato l'ecosistema \emph{Elastic Stack}, \emph{Docker} e \emph{OpenTelemetry}. \\
L'applicazione \emph{PetClinic} è strumentata tramite l'\emph{OpenTelemetry Java Agent}, che esporta metriche e tracce verso un \emph{OpenTelemetry Collector}. Quest'ultimo funge da punto di aggregazione e inoltra i dati al sistema \gls{apm} gestito da \emph{Elastic Agent} tramite \emph{Fleet}. \\
In parallelo, i log dell'applicazione vengono scritti su un file locale dal \emph{container} \emph{PetClinic} e successivamente raccolti da \emph{Logstash}, che li elabora e li inoltra verso \emph{Elasticsearch} seguendo una \emph{pipeline} personalizzata. \\
Per quanto riguarda la visualizzazione dei dati, è stato utilizzato \emph{Kibana}, tramite cui è possibile monitorare l'andamento dell'applicazione, creare \emph{dashboard}, analizzare metriche di \emph{performance}, effettuare ricerche sui log ed eseguire attività di \emph{anomaly detection}. \\
Accanto ai dati reali provenienti dall'applicazione, è stato integrato un sistema di \emph{Synthetic Monitoring} basato su \emph{Kibana Synthetics}, che utilizza \emph{script Playwright} per simulare il comportamento degli utenti e verificare la disponibilità e il corretto funzionamento dei principali flussi di navigazione. Trattandosi di un applicazione di prova infatti l'utilizzo di monitoraggio sintetico permette di lavorare con una quantità più significativa di dati. \\
Nel complesso, l'architettura si presenta come una \emph{pipeline} altamente modulare, in cui ogni componente è orchestrato tramite \emph{Docker Compose}. Questa struttura rende l'ambiente facilmente replicabile, facilitando sia le attività di sviluppo che quelle di \emph{troubleshooting}.
\begin{figure}[H] 
    \centering 
    \includegraphics[width=\columnwidth]{Architettura_complessiva.png}
    \caption{Figura 5.1 - Architettura complessiva}
\end{figure}

\newpage


\section{Struttura del progetto}
La realizzazione del sistema di osservabilità è stata accompagnata dalla definizione di una struttura del progetto che ne facilitasse lo sviluppo e le attività di manutenzione. \\
Il repository principale, chiamato \emph{elastic-project}, contiene tutte le componenti necessarie all'avvio tramite \emph{Docker Compose} e alla configurazione delle \emph{pipelines} di log, metriche e tracce, nonché all'avvio delle istanze del \emph{Fleet Server} e delle \emph{policy} per il \emph{Synthetic monitoring}. \\
La struttura complessiva è riportata di seguito:
\begin{lstlisting}[basicstyle=\ttfamily\small]
- elastic-project/ 
-- docker-compose.yml
-- .env
-- logstash.conf
-- logs/
-- collector/
    -> config.yaml
-- mcp-server-elasticsearch/
-- spring-petclinic/
    -> Dockerfile
\end{lstlisting}

Questa organizzazione è stata costruita con l'obiettivo di isolare le responsabilità dei vari componenti:
\begin{itemize}
    \item \textbf{docker-compose.yml} rappresenta il file principale per l'orchestrazione dei \emph{container}, in cui vengono definiti i servizi fondamentali. La scelta di accorpare tutti i servizi in un unico file semplifica la fase di avvio e garantisce un ambiente riproducibile;
    \item \textbf{spring-petclinic/} contiene il codice dell'applicazione \emph{PetClinic} e il relativo \emph{Dockerfile} per la creazione dell'immagine personalizzata con l'\emph{OpenTelemetry Java Agent} integrato;
    \item \textbf{collector/} include la configurazione dell'\emph{OpenTelemetry Collector} nel file \emph{config.yaml}, responsabile della ricezione dei dati \gls{otlp} provenienti da \emph{PetClinic} e del loro inoltro al sistema \gls{apm} gestito da \emph{Fleet};
    \item \textbf{logstash.conf} definisce la \emph{pipeline} di \emph{Logstash} che legge e filtra i log dell'applicazione, applicando un primo livello di arricchimento e inviando i dati a \emph{Elasticsearch};
    \item \textbf{logs/} funge da volume locale in cui l'applicazione \emph{PetClinic} rende disponibili i file di log;
    \item \textbf{mcp-server-elasticsearch/} contiene i file necessari per l'esecuzione del \emph{server} \gls{mcpg}\glsfirstoccur dedicato a \emph{Elasticsearch}, che abilita l'interazione con strumenti di \gls{ai} generativa come \emph{Claude Code};
    \item \textbf{.env} contiene le variabili d'ambiente necessarie per la configurazione dei servizi.
\end{itemize}
Questa struttura ha permesso di lavorare in modo indipendente sulle singole componenti del sistema senza introdurre interferenze tra servizi, e ha contribuito a semplificare la fase di diagnosi dei problemi.

\newpage


\section{Implementazione del logging}
L'implementazione della \emph{pipeline} di raccolta e indicizzazione dei log applicativi rappresenta un passaggio fondamentale del sistema di osservabilità sviluppato. \\
L'obiettivo principale era quello di acquisire i log generati da \emph{Spring PetClinic}, arricchirli con metadati utili, e renderli disponibili per la consultazione e l'analisi tramite \emph{Kibana}. \\
Per ottenere questo risultato è stata realizzata una \emph{pipeline} composta da tre elementi principali:
\begin{enumerate}
    \item scrittura dei log nel \emph{container PetClinic}, in un percorso montato come volume esterno;
    \item raccolta ed elaborazione dei log tramite \emph{Logstash}, configurato con un file di \emph{pipeline} dedicato;
    \item indicizzazione dei log in \emph{Elasticsearch} tramite una struttura di indici gestita con \gls{ilmg}\glsfirstoccur e un \emph{template} personalizzato.
\end{enumerate}

\subsection{Scrittura dei log applicativi}
Il primo passo ha riguardato la configurazione di \emph{PetClinic} affinché producesse log su file, in modo da poterli acquisire tramite \emph{Logstash}.
Il \emph{Dockerfile} dell'applicazione è stato modificato aggiungendo il parametro \texttt{-Dlogging.file.name=/var/log/petclinic/app.log} alla riga di comando di avvio. \\
Questo approccio ha permesso di centralizzare i log in un unico file, esporlo come volume condiviso e separare la fase di generazione dei log dalla loro elaborazione. 

\subsection{Pipeline Logstash}
La raccolta e trasformazione dei log è stata implementata tramite \emph{Logstash}, attraverso un file di configurazione dedicato \texttt{logstash.conf}:
\begin{lstlisting}
input {
  file {
    path => "/var/log/petclinic/app.log"
    start_position => "beginning"
    sincedb_path   => "/usr/share/logstash/data/sincedb-petclinic"
  }
}

filter {
  mutate {
    add_field => {
      "service.name"      => "petclinic"
      "event.dataset"     => "petclinic.app"
      "data_stream.type"  => "logs"
      "data_stream.dataset" => "petclinic"
      "data_stream.namespace" => "default"
    }
  }
}

output {
  stdout { codec => rubydebug }

  elasticsearch {
    hosts    => [ "${ELASTIC_HOSTS}" ]
    user     => "${ELASTIC_USER}"
    password => "${ELASTIC_PASSWORD}"
    ssl      => true
    cacert   => "/usr/share/logstash/certs/ca/ca.crt"
    index    => "petclinic-logs"
  }
}
\end{lstlisting}
La pipeline si articola in tre fasi: input, filtro e output.

\paragraph{Input:}
Viene utilizzato il plugin \texttt{file} per monitorare il file \texttt{app.log} generato dall'applicazione.  
Il file viene letto dall'inizio e l'avanzamento è tracciato tramite un file \texttt{sincedb}, così da evitare duplicazioni in caso di riavvio.

\paragraph{Filter:}
I log vengono arricchiti con metadati aggiuntivi, tra cui:
\begin{itemize}
    \item \texttt{service.name},
    \item \texttt{event.dataset},
    \item campi relativi ai data stream di \emph{Elasticsearch}.
\end{itemize}
Queste informazioni migliorano la struttura dei documenti, permettendo un'analisi più efficace e una migliore organizzazione dei dati nei \emph{data view}.

\paragraph{Output:}
L'output della pipeline invia i documenti verso \emph{Elasticsearch} tramite l'endpoint \gls{httpsg}\glsfirstoccur, utilizzando credenziali e certificati definiti nel file \texttt{.env}.  
I log vengono scritti sull'alias \texttt{petclinic-logs}, gestito successivamente tramite \gls{ilmg}.

\subsection{Struttura degli indici in Elasticsearch}
Prima dell'invio dei log è stata predisposta l'infrastruttura necessaria in \emph{Elasticsearch}.

\paragraph{Policy ILM:}
È stata definita una policy di gestione del ciclo di vita dell'indice (\emph{Index Lifecycle Management}) in grado di:
\begin{itemize}
    \item effettuare \emph{rollover} ogni 1 GB o ogni 24 ore;
    \item eliminare automaticamente i dati più vecchi dopo 7 giorni.
\end{itemize}
strutturata come segue:
\begin{lstlisting}
PUT _ilm/policy/petclinic-logs-ilm
{
  "policy": {
    "phases": {
      "hot": {
        "actions": {
          "rollover": {
            "max_size": "1gb",
            "max_age": "1d"
          }
        }
      },
      "delete": {
        "min_age": "7d",
        "actions": {
          "delete": {}
        }
      }
    }
  }
}
\end{lstlisting}

\paragraph{Index Template:}
È stato creato un \emph{template} denominato \texttt{petclinic-logs-template} per definire:
\begin{itemize}
    \item il numero di \emph{shard} e repliche,
    \item il limite massimo dei campi mappati,
    \item il \emph{mapping} dei principali campi del log,
    \item regole dinamiche per trattare le stringhe come \emph{keyword}.
\end{itemize}
\begin{lstlisting}
PUT _index_template/petclinic-logs-template
{
  "index_patterns": ["petclinic-logs-*"],
  "template": {
    "settings": {
      "index.lifecycle.name": "petclinic-logs-ilm",
      "index.lifecycle.rollover_alias": "petclinic-logs",
      "number_of_shards": 1,
      "number_of_replicas": 0,
      "index.mapping.total_fields.limit": 2000,
    },
    "mappings": {
      "dynamic": true,
      "properties": {
        "@timestamp": {
          "type": "date"
        },

        "message": {
          "type": "text",
          "fields": {
            "keyword": { "type": "keyword", "ignore_above": 256 }
          }
        },

        "log.level":       { "type": "keyword" },
        "log.logger":      { "type": "keyword" },
        "log.thread":      { "type": "keyword" },
        "log.original":    { "type": "text" },

        "service.name":    { "type": "keyword" },
        "event.dataset":   { "type": "keyword" },

        "trace.id": { 
          "type": "keyword",
          "ignore_above": 256
        },
        "span.id": {
          "type": "keyword",
          "ignore_above": 256
        },

        "error": {
          "properties": {
            "type":     { "type": "keyword" },
            "message":  { "type": "text" },
            "stack":    { "type": "text" }
          }
        }
      },

      "dynamic_templates": [
        {
          "strings_as_keywords": {
            "match_mapping_type": "string",
            "mapping": { "type": "keyword", "ignore_above": 256 }
          }
        }
      ]
    }
  },
  "_meta": {
    "description": "Template index per petclinic"
  }
}
\end{lstlisting}

\paragraph{Alias e primo indice:}
È stato infine creato il primo indice gestito dalla \emph{policy} \gls{ilmg}, associato all'\emph{alias} \texttt{petclinic-logs} con \texttt{is\_write\_index = true}, in questo modo \emph{Logstash} scrive sempre nell'\emph{alias}, mentre \emph{Elasticsearch} gestisce la creazione dei nuovi indici tramite \gls{ilmg}:
\begin{lstlisting}
PUT petclinic-logs-000001
{
  "aliases": {
    "petclinic-logs": {
      "is_write_index": true
    }
  }
}
\end{lstlisting}


\subsection{Risultato della pipeline}
La \emph{pipeline} finale dei log può essere sintetizzata nel seguente flusso:
\begin{figure}[H] 
    \centering 
    \includegraphics[width=\columnwidth]{pipeline_logs.png} 
    \caption{Figura 5.2 - Pipeline Logs}
\end{figure}
Grazie a questa configurazione viene garantita un'acquisizione affidabile dei log, un arricchimento consistente delle informazioni e una consultazione efficace tramite \emph{Kibana}.
%\texttt{PetClinic (scrive /var/log/petclinic/app.log) -> Logstash -> Elasticsearch (ILM + index template petclinic-logs-*) -> Kibana (Data View “petclinic-logs”)}

\newpage


\section{Implementazione di traces e metrics}
Parallelamente alla \emph{pipeline} dei log, è stata realizzata una \emph{pipeline} dedicata alla raccolta di metriche e tracce distribuite generate dalla \emph{web app PetClinic}. \\
L'obiettivo è stato quello di ottenere una visione approfondita sui tempi di risposta, sui flussi di esecuzione delle richieste e sulle interazioni tra i componenti del sistema. 
Per raggiungere questo risultato è stato adottato \emph{OpenTelemetry}, integrato con l'\emph{Elastic APM} tramite \emph{Fleet}. \\
La \emph{pipeline} completa è composta dai seguenti elementi:
\begin{enumerate}
    \item strumentazione automatica dell'applicazione tramite \emph{OpenTelemetry Java Agent};
    \item raccolta dei dati \gls{otlpg} (\emph{OpenTelemetry Protocol}) da parte dell'\emph{OpenTelemetry Collector};
    \item inoltro dei dati verso l'\emph{APM Server} gestito dall'\emph{Elastic Agent};
    \item indicizzazione delle metriche e delle tracce in \emph{Elasticsearch} e visualizzazione in \emph{Kibana}.
\end{enumerate}


\subsection{Strumentazione dell'applicazione con OpenTelemetry Java Agent}
L'applicazione \emph{PetClinic} è stata strumentata utilizzando l'\emph{OpenTelemetry Java Agent}, un agente Java esterno che permette di raccogliere automaticamente metriche e tracce senza modifiche al codice sorgente. \\
Nel \texttt{Dockerfile} dell'applicazione sono stati aggiunti:
\begin{itemize}
    \item il file \texttt{opentelemetry-javaagent.jar};
    \item i parametri di avvio per abilitarne il caricamento e configurarne l'esportazione.
\end{itemize}
Il comando di avvio che viene eseguito dal \texttt{Dockerfile} è il seguente:
\begin{verbatim}
CMD ["java", \
    "-javaagent:/app/opentelemetry-javaagent.jar", \
    "-Dotel.service.name=petclinic", \
    "-Dotel.exporter.otlp.endpoint=http://collector:4318", \
    "-Dotel.exporter.otlp.protocol=http/protobuf", \
    "-Dotel.exporter.otlp.insecure=true", \
    "-Dlogging.file.name=/var/log/petclinic/app.log", \
    "-jar", "/app/app.jar"]
\end{verbatim}
Grazie a questa configurazione, l'applicazione esporta automaticamente:
\begin{itemize}
    \item metriche sulle performance (\gls{cpug}, \emph{heap}, ecc);
    \item tracce delle richieste \gls{httpg} in ingresso;
    \item eventi relativi agli errori e alle eccezioni.
\end{itemize}


\subsection{RUM Agent per la raccolta di metriche e tracce lato frontend}
Oltre ai dati provenienti dal backend tramite l'\emph{OpenTelemetry Java Agent}, la \emph{pipeline} raccoglie anche metriche, errori e tracce generate dal \emph{frontend} dell'applicazione attraverso il \emph{RUM Agent} di \emph{Elastic APM}. \\
Il \emph{RUM Agent}, integrato direttamente nelle pagine \emph{web}, invia i dati di \emph{performance} del \emph{browser}, la durata delle transazioni utente, gli errori \emph{JavaScript} e le informazioni sulla navigazione direttamente all'\emph{APM Server}. \\
Il \emph{RUM Agent}, a differenza dell'\emph{OpenTelemetry Collector}, comunica nativamente con il protocollo \emph{Elastic APM} e invia i dati direttamente all'endpoint \gls{apmg}, senza transitare attraverso il \emph{Collector}. \\
Entrambe le sorgenti, confluiscono nei data stream \texttt{traces-apm*} e \texttt{metrics-apm*}, permettendo una visione unificata delle performance sia del \emph{backend} sia del \emph{frontend}.


\subsection{OpenTelemetry Collector}
Il \emph{Collector} funge da punto di raccolta per i dati \gls{otlpg} provenienti dalla \emph{web app}. 
In questo progetto è stato configurato in modalità \emph{gateway}, aggregando i dati e inoltrandoli al sistema \gls{apmg} gestito da \emph{Elastic}. \\
Il file \texttt{config.yaml} definisce i seguenti componenti principali:
\begin{itemize}
    \item un \texttt{receiver} \gls{otlpg} (\gls{httpg} e \gls{grpcg}\glsfirstoccur) per ricevere i dati dall'applicazione;
    \item un processore \texttt{memory\_limiter} per evitare sovraccarichi;
    \item un processore \texttt{batch} per inviare i dati in blocchi ottimizzati;
    \item un \texttt{exporter} \texttt{otlphttp/elastic} diretto verso il container \texttt{apm-agent}.
\end{itemize}
Il \emph{collector} è eseguito come servizio dedicato nel \texttt{docker-compose}, con volume in sola lettura. \\
Ecco la configurazione completa:
\begin{lstlisting}
receivers:
  otlp:
    protocols:
      grpc:
        endpoint: 0.0.0.0:4317
      http:
        endpoint: 0.0.0.0:4318
        cors:
          allowed_origins: ["http://localhost:*", "http://127.0.0.1:*", "*"]
          allowed_headers: ["*"]

processors:
  memory_limiter:
    check_interval: 2s
    limit_percentage: 80
    spike_limit_percentage: 25
  batch:
    timeout: 2s
    send_batch_size: 1024


exporters:
  otlphttp/elastic:
    endpoint: "http://apm-agent:8200"
    tls:
      insecure: true

service:
  pipelines:
    traces:
      receivers: [otlp]
      processors: [memory_limiter, batch]
      exporters: [otlphttp/elastic]
    metrics:
      receivers: [otlp]
      processors: [memory_limiter, batch]
      exporters: [otlphttp/elastic]
    logs:
      receivers: [otlp]
      processors: [memory_limiter, batch]
      exporters: [otlphttp/elastic]
\end{lstlisting}


\subsection{Elastic Agent e APM Server}
Il sistema \gls{apmg} di \emph{Elastic} è gestito tramite l'\emph{Elastic Agent} registrato in \emph{Fleet}. 
Nel progetto è stato utilizzato un \emph{container} dedicato (\texttt{apm-agent}) configurato per:
\begin{itemize}
    \item registrarsi automaticamente presso il \emph{Fleet Server} tramite \emph{enrollement token};
    \item esporre l'\emph{endpoint} \gls{apmg} sulla porta 8200;
    \item ricevere dati \gls{otlpg} dal \emph{Collector}.
\end{itemize}
L'\emph{APM Server} è responsabile di:
\begin{itemize}
    \item validare metriche e tracce in arrivo;
    \item convertirle nei documenti \emph{Elasticsearch};
    \item indicizzarle automaticamente in base ai moduli di ingesione dello \emph{stack Elastic}.
\end{itemize}
La corretta registrazione del \emph{container} in \emph{Fleet} è un prerequisito per il funzionamento della \emph{pipeline}, a tal fine, è stata dedicata un'apposita \emph{policy APM}.


\subsection{Indicizzazione e visualizzazione dei dati in Kibana}
Una volta ricevuti dal sistema \gls{apmg}, i dati vengono indicizzati in \emph{Elasticsearch} nei \emph{data stream}:
\begin{itemize}
    \item \texttt{traces-apm*} per le tracce distribuite;
    \item \texttt{metrics-apm*} per le metriche;
    \item \texttt{logs-apm*} per eventuali eventi generati dall'agente.
\end{itemize}
Questi indici vengono raccolti automaticamente nella data view \texttt{APM}, fornita nativamente dalla piattaforma.


\subsection{Risultato della pipeline}
Il flusso risultante può essere sintetizzato come segue:
\begin{figure}[H] 
    \centering 
    \includegraphics[width=\columnwidth]{pipeline_traces_metrics.png} 
    \caption{Figura 5.3 - Pipeline Traces e Metrics}
\end{figure}

\newpage


\section{Containerizzazione con Docker Compose}



\section{Visualizzazione dei dati in Kibana}



\section{Creazione delle dashboard}



\subsection{Dashboard Frontend - User Journey}



\subsection{Dashboard Backend - Health \& Stability}



\section{Machine Learning e Anomaly Detection}



\section{Synthetic Monitoring mediante Playwright e Kibana Synthetics}



\section{Integrazione con MCP Server e strumenti AI}



\section{Sintesi dei flussi end-to-end implementati}