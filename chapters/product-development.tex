\chapter{Sviluppo del prodotto}
\label{cap:product-development}

\intro{In questo capitolo vengono approfondite le fasi di sviluppo del sistema, descrivendo l'architettura complessiva, le fasi di implementazione e i risultati ottenuti}

\section{Architettura complessiva del sistema}
L'architettura realizzata durante il tirocinio ha l'obiettivo di fornire un sistema completo di osservabilità per la \emph{web app PetClinic}, integrando in un ambiente unico la raccolta dei log, metriche, tracce e monitoraggio sintetico. \\
Per raggiungere questo obiettivo è stato utilizzato l'ecosistema \emph{Elastic Stack}, \emph{Docker} e \emph{OpenTelemetry}. \\
L'applicazione \emph{PetClinic} è strumentata tramite l'\emph{OpenTelemetry Java Agent}, che esporta metriche e tracce verso un \emph{OpenTelemetry Collector}. Quest'ultimo funge da punto di aggregazione e inoltra i dati al sistema \gls{apm} gestito da \emph{Elastic Agent} tramite \emph{Fleet}. \\
In parallelo, i log dell'applicazione vengono scritti su un file locale dal \emph{container} \emph{PetClinic} e successivamente raccolti da \emph{Logstash}, che li elabora e li inoltra verso \emph{Elasticsearch} seguendo una \emph{pipeline} personalizzata. \\
Per quanto riguarda la visualizzazione dei dati, è stato utilizzato \emph{Kibana}, tramite cui è possibile monitorare l'andamento dell'applicazione, creare \emph{dashboard}, analizzare metriche di \emph{performance}, effettuare ricerche sui log ed eseguire attività di \emph{anomaly detection}. \\
Accanto ai dati reali provenienti dall'applicazione, è stato integrato un sistema di \emph{Synthetic Monitoring} basato su \emph{Kibana Synthetics}, che utilizza \emph{script Playwright} per simulare il comportamento degli utenti e verificare la disponibilità e il corretto funzionamento dei principali flussi di navigazione. Trattandosi di un applicazione di prova infatti l'utilizzo di monitoraggio sintetico permette di lavorare con una quantità più significativa di dati. \\
Nel complesso, l'architettura si presenta come una \emph{pipeline} altamente modulare, in cui ogni componente è orchestrato tramite \emph{Docker Compose}. Questa struttura rende l'ambiente facilmente replicabile, facilitando sia le attività di sviluppo che quelle di \emph{troubleshooting}.
\begin{figure}[H] 
    \centering 
    \includegraphics[width=\columnwidth]{Architettura_complessiva.png}
    \caption{Figura 5.1 - Architettura complessiva}
\end{figure}

\newpage


\section{Struttura del progetto}
La realizzazione del sistema di osservabilità è stata accompagnata dalla definizione di una struttura del progetto che ne facilitasse lo sviluppo e le attività di manutenzione. \\
Il repository principale, chiamato \emph{elastic-project}, contiene tutte le componenti necessarie all'avvio tramite \emph{Docker Compose} e alla configurazione delle \emph{pipelines} di log, metriche e tracce, nonché all'avvio delle istanze del \emph{Fleet Server} e delle \emph{policy} per il \emph{Synthetic monitoring}. \\
La struttura complessiva è riportata di seguito:
\begin{lstlisting}[basicstyle=\ttfamily\small]
- elastic-project/ 
-- docker-compose.yml
-- .env
-- logstash.conf
-- logs/
-- collector/
    -> config.yaml
-- mcp-server-elasticsearch/
-- spring-petclinic/
    -> Dockerfile
\end{lstlisting}

Questa organizzazione è stata costruita con l'obiettivo di isolare le responsabilità dei vari componenti:
\begin{itemize}
    \item \textbf{docker-compose.yml} rappresenta il file principale per l'orchestrazione dei \emph{container}, in cui vengono definiti i servizi fondamentali. La scelta di accorpare tutti i servizi in un unico file semplifica la fase di avvio e garantisce un ambiente riproducibile;
    \item \textbf{spring-petclinic/} contiene il codice dell'applicazione \emph{PetClinic} e il relativo \emph{Dockerfile} per la creazione dell'immagine personalizzata con l'\emph{OpenTelemetry Java Agent} integrato;
    \item \textbf{collector/} include la configurazione dell'\emph{OpenTelemetry Collector} nel file \emph{config.yaml}, responsabile della ricezione dei dati \gls{otlp} provenienti da \emph{PetClinic} e del loro inoltro al sistema \gls{apm} gestito da \emph{Fleet};
    \item \textbf{logstash.conf} definisce la \emph{pipeline} di \emph{Logstash} che legge e filtra i log dell'applicazione, applicando un primo livello di arricchimento e inviando i dati a \emph{Elasticsearch};
    \item \textbf{logs/} funge da volume locale in cui l'applicazione \emph{PetClinic} rende disponibili i file di log;
    \item \textbf{mcp-server-elasticsearch/} contiene i file necessari per l'esecuzione del \emph{server} \gls{mcpg}\glsfirstoccur dedicato a \emph{Elasticsearch}, che abilita l'interazione con strumenti di \gls{ai} generativa come \emph{Claude Code};
    \item \textbf{.env} contiene le variabili d'ambiente necessarie per la configurazione dei servizi.
\end{itemize}
Questa struttura ha permesso di lavorare in modo indipendente sulle singole componenti del sistema senza introdurre interferenze tra servizi, e ha contribuito a semplificare la fase di diagnosi dei problemi.

\newpage


\section{Implementazione del logging}
L'implementazione della \emph{pipeline} di raccolta e indicizzazione dei log applicativi rappresenta un passaggio fondamentale del sistema di osservabilità sviluppato. \\
L'obiettivo principale era quello di acquisire i log generati da \emph{Spring PetClinic}, arricchirli con metadati utili, e renderli disponibili per la consultazione e l'analisi tramite \emph{Kibana}. \\
Per ottenere questo risultato è stata realizzata una \emph{pipeline} composta da tre elementi principali:
\begin{enumerate}
    \item scrittura dei log nel \emph{container PetClinic}, in un percorso montato come volume esterno;
    \item raccolta ed elaborazione dei log tramite \emph{Logstash}, configurato con un file di \emph{pipeline} dedicato;
    \item indicizzazione dei log in \emph{Elasticsearch} tramite una struttura di indici gestita con \gls{ilmg}\glsfirstoccur e un \emph{template} personalizzato.
\end{enumerate}

\subsection{Scrittura dei log applicativi}
Il primo passo ha riguardato la configurazione di \emph{PetClinic} affinché producesse log su file, in modo da poterli acquisire tramite \emph{Logstash}.
Il \emph{Dockerfile} dell'applicazione è stato modificato aggiungendo il parametro \texttt{-Dlogging.file.name=/var/log/petclinic/app.log} alla riga di comando di avvio. \\
Questo approccio ha permesso di centralizzare i log in un unico file, esporlo come volume condiviso e separare la fase di generazione dei log dalla loro elaborazione. 

\subsection{Pipeline Logstash}
La raccolta e trasformazione dei log è stata implementata tramite \emph{Logstash}, attraverso un file di configurazione dedicato \texttt{logstash.conf}:
\begin{lstlisting}
input {
  file {
    path => "/var/log/petclinic/app.log"
    start_position => "beginning"
    sincedb_path   => "/usr/share/logstash/data/sincedb-petclinic"
  }
}

filter {
  mutate {
    add_field => {
      "service.name"      => "petclinic"
      "event.dataset"     => "petclinic.app"
      "data_stream.type"  => "logs"
      "data_stream.dataset" => "petclinic"
      "data_stream.namespace" => "default"
    }
  }
}

output {
  stdout { codec => rubydebug }

  elasticsearch {
    hosts    => [ "${ELASTIC_HOSTS}" ]
    user     => "${ELASTIC_USER}"
    password => "${ELASTIC_PASSWORD}"
    ssl      => true
    cacert   => "/usr/share/logstash/certs/ca/ca.crt"
    index    => "petclinic-logs"
  }
}
\end{lstlisting}
La pipeline si articola in tre fasi: input, filtro e output.

\paragraph{Input:}
Viene utilizzato il plugin \texttt{file} per monitorare il file \texttt{app.log} generato dall'applicazione.  
Il file viene letto dall'inizio e l'avanzamento è tracciato tramite un file \texttt{sincedb}, così da evitare duplicazioni in caso di riavvio.

\paragraph{Filter:}
I log vengono arricchiti con metadati aggiuntivi, tra cui:
\begin{itemize}
    \item \texttt{service.name},
    \item \texttt{event.dataset},
    \item campi relativi ai data stream di \emph{Elasticsearch}.
\end{itemize}
Queste informazioni migliorano la struttura dei documenti, permettendo un'analisi più efficace e una migliore organizzazione dei dati nei \emph{data view}.

\paragraph{Output:}
L'output della pipeline invia i documenti verso \emph{Elasticsearch} tramite l'endpoint \gls{httpsg}\glsfirstoccur, utilizzando credenziali e certificati definiti nel file \texttt{.env}.  
I log vengono scritti sull'alias \texttt{petclinic-logs}, gestito successivamente tramite \gls{ilmg}.

\subsection{Struttura degli indici in Elasticsearch}
Prima dell'invio dei log è stata predisposta l'infrastruttura necessaria in \emph{Elasticsearch}.

\paragraph{Policy ILM:}
È stata definita una policy di gestione del ciclo di vita dell'indice (\emph{Index Lifecycle Management}) in grado di:
\begin{itemize}
    \item effettuare \emph{rollover} ogni 1 GB o ogni 24 ore;
    \item eliminare automaticamente i dati più vecchi dopo 7 giorni.
\end{itemize}
strutturata come segue:
\begin{lstlisting}
PUT _ilm/policy/petclinic-logs-ilm
{
  "policy": {
    "phases": {
      "hot": {
        "actions": {
          "rollover": {
            "max_size": "1gb",
            "max_age": "1d"
          }
        }
      },
      "delete": {
        "min_age": "7d",
        "actions": {
          "delete": {}
        }
      }
    }
  }
}
\end{lstlisting}

\paragraph{Index Template:}
È stato creato un \emph{template} denominato \texttt{petclinic-logs-template} per definire:
\begin{itemize}
    \item il numero di \emph{shard} e repliche,
    \item il limite massimo dei campi mappati,
    \item il \emph{mapping} dei principali campi del log,
    \item regole dinamiche per trattare le stringhe come \emph{keyword}.
\end{itemize}
\begin{lstlisting}
PUT _index_template/petclinic-logs-template
{
  "index_patterns": ["petclinic-logs-*"],
  "template": {
    "settings": {
      "index.lifecycle.name": "petclinic-logs-ilm",
      "index.lifecycle.rollover_alias": "petclinic-logs",
      "number_of_shards": 1,
      "number_of_replicas": 0,
      "index.mapping.total_fields.limit": 2000,
    },
    "mappings": {
      "dynamic": true,
      "properties": {
        "@timestamp": {
          "type": "date"
        },

        "message": {
          "type": "text",
          "fields": {
            "keyword": { "type": "keyword", "ignore_above": 256 }
          }
        },

        "log.level":       { "type": "keyword" },
        "log.logger":      { "type": "keyword" },
        "log.thread":      { "type": "keyword" },
        "log.original":    { "type": "text" },

        "service.name":    { "type": "keyword" },
        "event.dataset":   { "type": "keyword" },

        "trace.id": { 
          "type": "keyword",
          "ignore_above": 256
        },
        "span.id": {
          "type": "keyword",
          "ignore_above": 256
        },

        "error": {
          "properties": {
            "type":     { "type": "keyword" },
            "message":  { "type": "text" },
            "stack":    { "type": "text" }
          }
        }
      },

      "dynamic_templates": [
        {
          "strings_as_keywords": {
            "match_mapping_type": "string",
            "mapping": { "type": "keyword", "ignore_above": 256 }
          }
        }
      ]
    }
  },
  "_meta": {
    "description": "Template index per petclinic"
  }
}
\end{lstlisting}

\paragraph{Alias e primo indice:}
È stato infine creato il primo indice gestito dalla \emph{policy} \gls{ilmg}, associato all'\emph{alias} \texttt{petclinic-logs} con \texttt{is\_write\_index = true}, in questo modo \emph{Logstash} scrive sempre nell'\emph{alias}, mentre \emph{Elasticsearch} gestisce la creazione dei nuovi indici tramite \gls{ilmg}:
\begin{lstlisting}
PUT petclinic-logs-000001
{
  "aliases": {
    "petclinic-logs": {
      "is_write_index": true
    }
  }
}
\end{lstlisting}


\subsection{Risultato della pipeline}
La \emph{pipeline} finale dei log può essere sintetizzata nel seguente flusso:
\begin{figure}[H] 
    \centering 
    \includegraphics[width=\columnwidth]{pipeline_logs.png} 
    \caption{Figura 5.2 - Pipeline Logs}
\end{figure}
Grazie a questa configurazione viene garantita un'acquisizione affidabile dei log, un arricchimento consistente delle informazioni e una consultazione efficace tramite \emph{Kibana}.
%\texttt{PetClinic (scrive /var/log/petclinic/app.log) -> Logstash -> Elasticsearch (ILM + index template petclinic-logs-*) -> Kibana (Data View “petclinic-logs”)}

\newpage


\section{Implementazione di traces e metrics}
Parallelamente alla \emph{pipeline} dei log, è stata realizzata una \emph{pipeline} dedicata alla raccolta di metriche e tracce distribuite generate dalla \emph{web app PetClinic}. \\
L'obiettivo è stato quello di ottenere una visione approfondita sui tempi di risposta, sui flussi di esecuzione delle richieste e sulle interazioni tra i componenti del sistema. 
Per raggiungere questo risultato è stato adottato \emph{OpenTelemetry}, integrato con l'\emph{Elastic APM} tramite \emph{Fleet}. \\
La \emph{pipeline} completa è composta dai seguenti elementi:
\begin{enumerate}
    \item strumentazione automatica dell'applicazione tramite \emph{OpenTelemetry Java Agent};
    \item raccolta dei dati \gls{otlpg} (\emph{OpenTelemetry Protocol}) da parte dell'\emph{OpenTelemetry Collector};
    \item inoltro dei dati verso l'\emph{APM Server} gestito dall'\emph{Elastic Agent};
    \item indicizzazione delle metriche e delle tracce in \emph{Elasticsearch} e visualizzazione in \emph{Kibana}.
\end{enumerate}


\subsection{Strumentazione dell'applicazione}
L'applicazione \emph{PetClinic} è stata strumentata utilizzando l'\emph{OpenTelemetry Java Agent}, un agente Java esterno che permette di raccogliere automaticamente metriche e tracce senza modifiche al codice sorgente. \\
Nel \texttt{Dockerfile} dell'applicazione sono stati aggiunti:
\begin{itemize}
    \item il file \texttt{opentelemetry-javaagent.jar};
    \item i parametri di avvio per abilitarne il caricamento e configurarne l'esportazione.
\end{itemize}
Il comando di avvio che viene eseguito dal \texttt{Dockerfile} è il seguente:
\begin{verbatim}
CMD ["java", \
    "-javaagent:/app/opentelemetry-javaagent.jar", \
    "-Dotel.service.name=petclinic", \
    "-Dotel.exporter.otlp.endpoint=http://collector:4318", \
    "-Dotel.exporter.otlp.protocol=http/protobuf", \
    "-Dotel.exporter.otlp.insecure=true", \
    "-Dlogging.file.name=/var/log/petclinic/app.log", \
    "-jar", "/app/app.jar"]
\end{verbatim}
Grazie a questa configurazione, l'applicazione esporta automaticamente:
\begin{itemize}
    \item metriche sulle performance (\gls{cpug}, \emph{heap}, ecc);
    \item tracce delle richieste \gls{httpg} in ingresso;
    \item eventi relativi agli errori e alle eccezioni.
\end{itemize}


\subsection{RUM Agent frontend}
Oltre ai dati provenienti dal backend tramite l'\emph{OpenTelemetry Java Agent}, la \emph{pipeline} raccoglie anche metriche, errori e tracce generate dal \emph{frontend} dell'applicazione attraverso il \emph{RUM Agent} di \emph{Elastic APM}. \\
Il \emph{RUM Agent}, integrato direttamente nelle pagine \emph{web}, invia i dati di \emph{performance} del \emph{browser}, la durata delle transazioni utente, gli errori \emph{JavaScript} e le informazioni sulla navigazione direttamente all'\emph{APM Server}. \\
Il \emph{RUM Agent}, a differenza dell'\emph{OpenTelemetry Collector}, comunica nativamente con il protocollo \emph{Elastic APM} e invia i dati direttamente all'endpoint \gls{apmg}, senza transitare attraverso il \emph{Collector}. \\
Entrambe le sorgenti, confluiscono nei data stream \texttt{traces-apm*} e \texttt{metrics-apm*}, permettendo una visione unificata delle performance sia del \emph{backend} sia del \emph{frontend}.


\subsection{OpenTelemetry Collector}
Il \emph{Collector} funge da punto di raccolta per i dati \gls{otlpg} provenienti dalla \emph{web app}. 
In questo progetto è stato configurato in modalità \emph{gateway}, aggregando i dati e inoltrandoli al sistema \gls{apmg} gestito da \emph{Elastic}. \\
Il file \texttt{config.yaml} definisce i seguenti componenti principali:
\begin{itemize}
    \item un \texttt{receiver} \gls{otlpg} (\gls{httpg} e \gls{grpcg}\glsfirstoccur) per ricevere i dati dall'applicazione;
    \item un processore \texttt{memory\_limiter} per evitare sovraccarichi;
    \item un processore \texttt{batch} per inviare i dati in blocchi ottimizzati;
    \item un \texttt{exporter} \texttt{otlphttp/elastic} diretto verso il container \texttt{apm-agent}.
\end{itemize}
Il \emph{collector} è eseguito come servizio dedicato nel \texttt{docker-compose}, con volume in sola lettura. \\
Ecco la configurazione completa:
\begin{lstlisting}
receivers:
  otlp:
    protocols:
      grpc:
        endpoint: 0.0.0.0:4317
      http:
        endpoint: 0.0.0.0:4318
        cors:
          allowed_origins: ["http://localhost:*", "http://127.0.0.1:*", "*"]
          allowed_headers: ["*"]

processors:
  memory_limiter:
    check_interval: 2s
    limit_percentage: 80
    spike_limit_percentage: 25
  batch:
    timeout: 2s
    send_batch_size: 1024


exporters:
  otlphttp/elastic:
    endpoint: "http://apm-agent:8200"
    tls:
      insecure: true

service:
  pipelines:
    traces:
      receivers: [otlp]
      processors: [memory_limiter, batch]
      exporters: [otlphttp/elastic]
    metrics:
      receivers: [otlp]
      processors: [memory_limiter, batch]
      exporters: [otlphttp/elastic]
    logs:
      receivers: [otlp]
      processors: [memory_limiter, batch]
      exporters: [otlphttp/elastic]
\end{lstlisting}


\subsection{Elastic Agent e APM Server}
Il sistema \gls{apmg} di \emph{Elastic} è gestito tramite l'\emph{Elastic Agent} registrato in \emph{Fleet}. 
Nel progetto è stato utilizzato un \emph{container} dedicato (\texttt{apm-agent}) configurato per:
\begin{itemize}
    \item registrarsi automaticamente presso il \emph{Fleet Server} tramite \emph{enrollement token};
    \item esporre l'\emph{endpoint} \gls{apmg} sulla porta 8200;
    \item ricevere dati \gls{otlpg} dal \emph{Collector}.
\end{itemize}
L'\emph{APM Server} è responsabile di:
\begin{itemize}
    \item validare metriche e tracce in arrivo;
    \item convertirle nei documenti \emph{Elasticsearch};
    \item indicizzarle automaticamente in base ai moduli di ingesione dello \emph{stack Elastic}.
\end{itemize}
La corretta registrazione del \emph{container} in \emph{Fleet} è un prerequisito per il funzionamento della \emph{pipeline}, a tal fine, è stata dedicata un'apposita \emph{policy APM}.


\subsection{Indicizzazione e visualizzazione dei dati in Kibana}
Una volta ricevuti dal sistema \gls{apmg}, i dati vengono indicizzati in \emph{Elasticsearch} nei \emph{data stream}:
\begin{itemize}
    \item \texttt{traces-apm*} per le tracce distribuite;
    \item \texttt{metrics-apm*} per le metriche;
    \item \texttt{logs-apm*} per eventuali eventi generati dall'agente.
\end{itemize}
Questi indici vengono raccolti automaticamente nella data view \texttt{APM}, fornita nativamente dalla piattaforma.


\subsection{Risultato della pipeline}
Il flusso risultante può essere sintetizzato come segue:
\begin{figure}[H] 
    \centering 
    \includegraphics[width=\columnwidth]{pipeline_traces_metrics.png} 
    \caption{Figura 5.3 - Pipeline Traces e Metrics}
\end{figure}

\newpage


\section{Containerizzazione con Docker Compose}
L'intera infrastruttura di osservabilità è stata containerizzata utilizzando \emph{Docker Compose}, con lo scopo di ottenere un ambiente completamente riproducibile, isolato e facilmente avviabile. \\
Il file \texttt{docker-compose.yml} rappresenta il punto centrale dell'orchestrazione e descrive un insieme eterogeneo di servizi che lavorano assieme, tra cui:
\begin{itemize}
    \item \texttt{es01}: nodo \emph{Elasticsearch} responsabile della memorizzazione dei log, delle metriche e delle tracce;
    \item \texttt{kibana}: interfaccia grafica per la visualizzazione dei dati;
    \item \texttt{fleet-server}: servizio dedicato alla gestione centralizzata degli agenti \emph{Elastic};
    \item \texttt{apm-agent}: componente che espone l'\emph{endpoint APM} per ricevere metriche e tracce dal \emph{Collector} e dal \emph{RUM Agent};
    \item \texttt{collector}: \emph{OpenTelemetry Collector} configurato in modalità \emph{gateway};
    \item \texttt{logstash01}: responsabile della \emph{pipeline} di elaborazione dei log applicativi;
    \item \texttt{petclinic}: applicazione oggetto del monitoraggio;
    \item \texttt{mysql}: \emph{database} a supporto dell'applicazione;
    \item \texttt{synthetics-agent}: componente dedicato al monitoraggio sintetico;
    \item \texttt{mcp-server-elasticsearch}: server \gls{mcpg} utilizzato per l'integrazione con strumenti di \gls{aig} generativa;
    \item \texttt{setup}: servizio dedicato alla generazione e distribuzione dei certificati \gls{tlsg}.
\end{itemize}


\subsection{Gestione dei certificati e della sicurezza}
Una parte rilevante dell'orchestrazione riguarda la gestione della sicurezza. \\
Il servizio \texttt{setup} genera automaticamente certificati autofirmati e li distribuisce agli altri container attraverso un volume condiviso. Questo passaggio è essenziale poiché i servizi dello \emph{stack Elastic} richiedono comunicazioni cifrate e autenticazione abilitata. \\
Il file \texttt{.env}, incluso nel progetto, contiene inoltre credenziali, porte e parametri di configurazione necessari all'avvio dei container.


\subsection{Coordinamento dell'avvio dei servizi}
La corretta gestione dell'ordine di avvio è stata un aspetto importante della configurazione. Alcuni servizi, come \texttt{fleet-server} e \texttt{apm-agent}, richiedono che \emph{Elasticsearch} sia completamente operativo prima di potersi registrare ed esporre i propri \emph{endpoint}. \\
Questo comportamento è stato gestito tramite direttive \texttt{depends\_on}, healthcheck e l'utilizzo di servizi come \texttt{setup}, che garantiscono la generazione dei certificati necessari al \emph{cluster}. \\
L'uso esplicito delle dipendenze e dei controlli di stato ha reso possibile evitare errori di avvio legati alla sincronizzazione tra i servizi, un problema frequente nelle architetture \emph{multi-container}.


\subsection{Risultato dell'orchestrazione}
L'orchestrazione basata su \emph{Docker Compose} consente di controllare e avviare l'intero ambiente di osservabilità tramite il comando:
\begin{verbatim}
docker compose up -d
\end{verbatim}
Questo approccio ha permesso di ottenere un sistema facilmente estendibile e semplice da mantenere. 

\newpage


\section{Visualizzazione dei dati in Kibana}
Al termine della configurazione delle \emph{pipeline} di log, metriche, tracce e monitoraggio, è stato necessario predisporre in \emph{Kibana} gli strumenti per la visualizzazione e l'analisi dei dati raccolti. \\
Sono stati individuati diversi \emph{data view}, alcuni già presenti di default in \emph{Kibana}, altri appositamente creati per facilitare l'accesso ai vari tipi di dati:
\begin{itemize}
    \item \texttt{traces-apm*}, fornita nativamente da Kibana, contenente le tracce distribuite provenienti dal \emph{backend} e dal \emph{frontend};
    \item \texttt{metrics-apm*}, fornita nativamente da Kibana, relativa alle metriche di sistema raccolte dall'\emph{OpenTelemetry Java Agent};
    \item \texttt{logs-apm*}, fornita nativamente da Kibana, include eventuali eventi generati dagli agenti \emph{Elastic};
    \item \texttt{petclinic-logs-*}, \emph{data view} dedicato ai log applicativi raccolti tramite \emph{Logstash} e indicizzati in \emph{Elasticsearch}.
\end{itemize}
Per facilitare l'analisi, sono state create due viste dati principali:
\begin{itemize}
    \item \textbf{APM}: fornita nativamente da \emph{Kibana}, che aggrega metriche, tracce ed errori provenienti dal \emph{backend}, dal \emph{frontend} e dal monitoraggio sintetico;
    \item \textbf{petclinic-logs}: vista personalizzata per l'esplorazione dei log applicativi indicizzati tramite la \emph{pipeline} \emph{Logstash}.
\end{itemize}


\subsection{Verifica dell'indicizzazione tramite Dev Tools}
Dopo l'avvio dei servizi, è stata effettuata una verifica manuale dell'indicizzazione tramite la console \emph{Dev Tools} di \emph{Kibana}. \\
Questo controllo è stato utile per confermare il corretto funzionamento della \emph{pipeline} di log e verificare che i documenti fossero instradati verso il data stream appropriato. \\
Alcuni esempi di query utilizzate sono:
\begin{itemize}
  \item \texttt{GET petclinic-logs-*/\_search?size=5} per verificare che i documenti applicativi arrivino all'indice corretto;
  \item \texttt{GET petclinic-logs-*/\_mapping} per verificare che il \emph{mapping} dei campi sia in linea con il template di indicizzazione.
\end{itemize}
La risposta di Elasticsearch ha confermato che:
\begin{itemize}
    \item \emph{Logstash} stava correttamente inviando i log verso l'alias \texttt{petclinic-logs};
    \item il \emph{Collector} e il \emph{RUM Agent} inviavano correttamente le tracce all'\emph{APM Server};
    \item tutti i documenti venivano mappati in base al \emph{template} configurato.
\end{itemize}

\newpage


\section{Creazione delle dashboard}





\subsection{Dashboard Frontend - User Journey}
\begin{figure}[H] 
    \centering 
    \includegraphics[width=\columnwidth]{/dashboards/Frontend_dashboard.png}
    \caption{Figura 5.4 - Dashboard Frontend - User Journey}
\end{figure}


\subsection{Dashboard Backend - Health \& Stability}
\begin{figure}[H] 
    \centering 
    \includegraphics[width=\columnwidth]{/dashboards/Backend_dashboard.png} 
    \caption{Figura 5.5 - Dashboard Backend - Health \& Stability}
\end{figure}

\newpage


\section{Machine Learning e Anomaly Detection}


\newpage


\section{Synthetic Monitoring}


\newpage


\section{Integrazione con MCP Server e strumenti AI}


\newpage


\section{Sintesi dei flussi end-to-end}